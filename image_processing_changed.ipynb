{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from YOLOv8_predict import extract_detections_pt\n",
    "from utils import parse_coco_dataset, crop_box, draw_objects, calculate_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize paths\n",
    "folder_with_images = '/data/datasets/model_validation/val_yolo/images'\n",
    "coco_annotations_file = '/data/datasets/model_validation/coco/annotations/instances_default.json'\n",
    "visualized_images = 'visualized_images'\n",
    "yolo_model_name = \"yolov8n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  functions\n",
    "def draw_and_save_coco(coco_annotations, result_folder):\n",
    "    os.makedirs(result_folder, exist_ok=True)\n",
    "    for image_filepath, objects in coco_annotations.items():\n",
    "        image = cv2.imread(image_filepath)\n",
    "        if image is None:\n",
    "            print(f\"Cannot read image. Check path {image_filepath}\")\n",
    "            continue\n",
    "        image = draw_objects(image, objects)\n",
    "        result_filepath = os.path.join(result_folder, os.path.split(image_filepath)[-1])\n",
    "        cv2.imwrite(result_filepath, image)\n",
    "\n",
    "def run_image_with_yolo(image, model):\n",
    "    detections = []\n",
    "    predicted_data = model(image)\n",
    "    for pred in predicted_data:\n",
    "        dets = extract_detections_pt(pred)\n",
    "        for det in dets:\n",
    "            label = det['label']\n",
    "            score = det['score']\n",
    "            box = crop_box(det['ltrb'], image.shape[:2])\n",
    "            detections.append({'label': label, 'ltrb': box, 'score': score})\n",
    "    return detections\n",
    "\n",
    "def process_images(image_filepaths, model, annotations={}, result_folder=None):\n",
    "    if result_folder: os.makedirs(result_folder, exist_ok=True)\n",
    "    images_annotations_detections = {}\n",
    "    for image_filepath in image_filepaths:\n",
    "        # read image\n",
    "        image = cv2.imread(image_filepath)\n",
    "        if image is None:\n",
    "            print(f\"Cannot read image. Check path {image_filepath}\")\n",
    "            continue\n",
    "        # get annotated objects if annotations provided\n",
    "        annotated_objects = annotations.get(image_filepath, [])\n",
    "        # get detections\n",
    "        detections = run_image_with_yolo(image, model)\n",
    "        # draw objects and save an image if required\n",
    "        if result_folder:\n",
    "            result_filepath = os.path.join(result_folder, os.path.split(image_filepath)[-1])\n",
    "            image = draw_objects(image, annotated_objects)\n",
    "            image = draw_objects(image, detections)\n",
    "            cv2.imwrite(result_filepath, image)\n",
    "        #  keep results for next evaluation\n",
    "        images_annotations_detections[image_filepath] = {\n",
    "            \"annotated_objects\": annotated_objects,\n",
    "            \"detections\": detections\n",
    "        }\n",
    "    return images_annotations_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_annotations = parse_coco_dataset(folder_with_images, coco_annotations_file)\n",
    "model = YOLO(yolo_model_name)\n",
    "images_annotations_detections = process_images(coco_annotations.keys(), model, coco_annotations, visualized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ious(img_filepath, data):\n",
    "    results = []\n",
    "    ground_truth_data = data['annotated_objects']\n",
    "    predicted_data = data['detections']\n",
    "    for gt_obj in ground_truth_data:\n",
    "            gt_label, gt_box = gt_obj['label'], gt_obj['ltrb']\n",
    "            for detection in predicted_data:\n",
    "                det_label, det_box, det_score = detection['label'], detection['ltrb'], detection['score']\n",
    "                if gt_label == det_label:\n",
    "                    iou = calculate_iou(gt_box, det_box)\n",
    "                    results.append({\n",
    "                        'img_filepath': img_filepath, \n",
    "                        'label': gt_label, \n",
    "                        'gt_box': gt_box,\n",
    "                        'det_box': det_box,\n",
    "                        'iou': iou})\n",
    "    return results\n",
    "img_filepaths = list(coco_annotations.keys())\n",
    "img_filepath  = img_filepaths[0]\n",
    "results = compute_ious(img_filepath, images_annotations_detections[img_filepath])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tp_fn_fp(ann_obj, detections, iou_threshold=0.7, conf_threshold=0.8):\n",
    "    def is_in(box, label, lst, iou_threshold, conf_threshold):\n",
    "        for obj in lst:\n",
    "            if not label == obj['label']: continue\n",
    "            if obj.get('score', 1.0) <= conf_threshold: continue\n",
    "            if calculate_iou(box, obj['ltrb']) < iou_threshold: continue\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    tp, fn = 0, 0\n",
    "    for gt in ann_obj:\n",
    "        if is_in(gt['ltrb'], gt['label'], detections, iou_threshold, conf_threshold): tp += 1\n",
    "        else: fn += 1\n",
    "    fp = 0\n",
    "    for pred in detections:\n",
    "        if is_in(pred['ltrb'], pred['label'], ann_obj, iou_threshold, conf_threshold): continue\n",
    "        else: fp += 1   \n",
    "    return tp, fn, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(images_annotations_detections, iou_threshold=0.7, conf_threshold=0.8):\n",
    "    tps, fns, fps = 0, 0, 0\n",
    "    for _, info in images_annotations_detections.items():\n",
    "        annotated_obj = info[\"annotated_objects\"]\n",
    "        detections = info['detections']\n",
    "        tp, fn, fp = get_tp_fn_fp(annotated_obj, detections, iou_threshold, conf_threshold)\n",
    "        tps += tp\n",
    "        fns += fn\n",
    "        fps += fp\n",
    "    # pre, rec, f1s\n",
    "    precision = tps/float(tps+fps) if tps+fps>0 else 0.0\n",
    "    recall = tps/float(tps+fns) if tps+fns>0 else 0.0\n",
    "    f1s = (2*precision*recall)/(precision+recall) if precision+recall>0 else 0.0\n",
    "    return tps, fns, fps, precision, recall, f1s\n",
    "\n",
    "img_filepaths = list(coco_annotations.keys())\n",
    "image_filepath  = img_filepaths[0]\n",
    "\n",
    "evaluate(images_annotations_detections, iou_threshold=0.7, conf_threshold=0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
